Pymagra.utilities.utilities
===========================

.. py:module:: Pymagra.utilities.utilities

.. autoapi-nested-parse::

   Last modified on Aug. 26, 2024

   @author: Hermann Zeyen <hermann.zeyen@universite-paris-saclay.fr>
            Universit√© Paris-Saclay, France



Classes
-------

.. autoapisummary::

   Pymagra.utilities.utilities.Utilities


Module Contents
---------------

.. py:class:: Utilities(main)

   Contains the following utility functions for program PyMaGra:

       - extract
       - clean_data
       - diurnal_correction
       - diurnal_variation
       - interpol_line
       - interpol_2D
       - extrapolate
       - gauss_transform
       - justify_lines_gaussian
       - matrixExtension
       - pole_Reduction
       - continuation
       - analyticSignal
       - horizontalDerivative2
       - horizontalDerivative
       - horizontalDerivative2
       - tilt



   .. py:attribute:: main


   .. py:attribute:: month_base
      :value: []



   .. py:attribute:: day_base
      :value: []



   .. py:attribute:: year_base
      :value: []



   .. py:attribute:: hour_base
      :value: []



   .. py:attribute:: minute_base
      :value: []



   .. py:attribute:: second_base
      :value: []



   .. py:attribute:: time_base
      :value: []



   .. py:attribute:: jday_base
      :value: []



   .. py:attribute:: base
      :value: []



   .. py:attribute:: grad_inter
      :value: []



   .. py:method:: extract(choice)

      Mark data segments for treatment as function of odd or even line number

      :param choice: may be:

                     - "all" (choose all lines)
                     - "odd" (choose odd lines, natural counting)
                     - "even" (choose even line numbers, natural counting)
                     - "N", "S", "W" or "E"
      :type choice: tuple of str



   .. py:method:: data_flatten(data)

      Data that are stored in dictionary data with one entrance per line are
      concatenated into one 1D numpy array

      :param data: contains for every line itself a dictionary with the following keys:

                   - "s1" : Data of sensor 1
                   - "s2" : Data of sensor 2
                   - "x", "y", "z": Coordinates of data
      :type data: dictionary with keys equal to line number

      :returns: * **s1** (*Numpy 1D float array*) -- Concatenated data of sensor 1
                * **s2** (*Numpy 1D float array*) -- Concatenated data of sensor 2
                * **x** (*Numpy 1D float array*) -- Concatenated x-coordinates of all data
                * **y** (*Numpy 1D float array*) -- Concatenated y-coordinates of all data
                * **z** (*Numpy 1D float array*) -- Concatenated z-coordinates of all data



   .. py:method:: clean_data(min_fix=None, max_fix=None, percent_down=None, percent_up=None)

      Set data to np.nan under certain conditions which may be:

      :param data: Contains data to be cleaned (see io.get_line).
      :type data: dictionary
      :param min_fix: All data below this value are set to nan.
      :type min_fix: float
      :param max_fix: All data above this value are set to nan.
      :type max_fix: float
      :param percent_down: The lowermost percentile values are set to nan
                           A value of 0.01 means that all values lower than the
                           1% quantile are set to None.
      :type percent_down: float
      :param percent_up: The uppermost percentile values are set to nan
                         A value of 0.01 means that all values higher than the
                         99% quantile are set to None.
      :type percent_up: float

      :returns: **data** -- Same structure as inpput data, but with with data outside defined
                limits set to np.nan
      :rtype: dictionary



   .. py:method:: julian2date(j_day, year)

      Function translates Julian day number to standard date.
      1st of January is Julian day number 1.

      :param j_day: Number of Julian day
      :type j_day: int
      :param year: Year in which to do the calculation (important to know whether
                   it is a leap year). May be 2 or 4 ciphers
      :type year: int

      :returns: * **day** (*int*) -- Day of month
                * **month** (*int*) -- Month in year



   .. py:method:: date2julian(day, month, year)

      Function translates month and day of month to Julian day of year.
      1st of January is Julian day number 1.

      :param day: Day of month (natural counting, starts at 1)
      :type day: int
      :param month: Month of year (natural counting, starts at 1 for January)
      :type month: int
      :param year: Year in which to do the calculation (important to know whether
                   it is a leap year). May be 2 or 4 ciphers
      :type year: int

      :returns: **j_day** -- Julian day of year
      :rtype: int



   .. py:method:: time2data(time, year)

      Convert seconds into julian day of year, hour, minute and second

      :param time: Time to be converted [s], based on julian day of year, i.e.
                   time = julian_day*86000+hour*3600+minute*60+second.
      :type time: may be a single float or a 1D numpy array

      :returns: * *All returned parameters have the same shape as time.*
                * **month** (*int*) -- month of year
                * **day** (*int*) -- day of month.
                * **h** (*int*) -- Hour.
                * **m** (*int*) -- minute.
                * **s** (*float*) -- second.



   .. py:method:: diurnal_correction(degree=3, diff_weight=5.0)

      Apply diurnal corrections
      The diurnal variations may come from base station data (function read_base)
      or, if no base station data exist, they are calculated in function
      diurnal_variation by fitting a polynomial of degree "degree" to the
      measured data. Data of different days are then fitted independently.

      Base station data (measured or calculated) are interpolated onto
      measurement times and simply subtracted from data. The process is done
      in situ, i.e. the values of arrays self.sensor1 and self.sensor2 are
      modified. If you need to keep the original data, you must copy them to
      other arrays before applying diurnal_correction

      :param degree: Degree of polynom to be fitted to data. The default is 3.
                     This parameter is only used if no base station data exist
      :type degree: int, optional
      :param diff_weight: If day_joint_flag is true, diff_weight defines the relative weight
                          for the fit of the differences along the block edges with respect
                          to the fit of the medians.
      :type diff_weight: float, optional



   .. py:method:: diurnal_variation(data, lines, degree=3, diff_weight=1.0)

      Calculate a fit of degree "degree" to the data of lines "lines" which
      will be used for correction of diurnal variations if not base station
      data exist

      :param lines: Numbers of the lines to be used for calculation of diurnal variations.
                    If several files have been loaded, acquired at different days, the
                    fit may be calculated independently for every day.
      :type lines: 1D numpy int array
      :param degree: Degree of polynom to be fitted to data. The default is 3.
      :type degree: int, optional
      :param diff_weight: If all blocks are inverted together, diff_weight is the weight
                          given to fit of differences along the edges with respect to fit
                          of medians in each block. The default is 1.
      :type diff_weight: float, optional

      :returns: * *Polynome coefficients (1D numpy array of size degree+1)* -- The polynome is calculated as
                  P[degree]+P[degree-1]*x+P[degree-2]*x**2...+P[0]*x**degree
                  If multiple blocks are fitted together, P contains a polynome for
                  each block, i.e. len(P) = (degree+1)*number_of_blocks
                * **tmn** (*float*) -- For the stability of polynome fit, times (given in seconds) are
                  reduced such that the minimum time is zero. tmn is this minumum time.
                  To apply the coefficients to data, their time must be transformed to
                  time-tmn before applying the polynome coefficients



   .. py:method:: interpol_line(nsensor, i_line=0, dx=0.2, xmin=0.0, xmax=0.0, k=3)

      interpolate data of one line onto a regular grid

      :param i_line: Number of line to be interpolated (counting starts at 0). The default is 0.
      :type i_line: int, optional
      :param dx: Sampling step in meters for interpolated data. The default is 0.2.
      :type dx: float, optional
      :param xmin: Position of first sample along self.direction in meters. The default is 0.
      :type xmin: float, optional
      :param xmax: Position of last sample along self.direction in meters. The default is 0.
      :type xmax: float, optional
      :param k: Degree of spline used for interpolation. The default is 3.
                See scipy.interpolate.interp1d for more information. Only splines are used.
                Correspondance between k and "kind" of scipy.interpolate.interp1d:

                - k=0: kind="zero"
                - k=1: kind="slinear"
                - k=2: kind="quadratic"
                - k=3: kind="cubic"
      :type k: int, optional
      :param If xmin == xmax:
      :param the starting and end points are calculated automatically.:
      :param For this:
      :param the starting point is placed at the nearest multiple of dx for:
      :param the coordinate of self.direction (see function read_stn):

      :returns: * **sensor_inter** (*numpy float array*) -- Interpolated data
                * **x_inter** (*numpy float array*) -- Interpolated X-coordinates
                * **y_inter** (*numpy float array*) -- Interpolated Y-coordinates
                * **dmin** (*float*) -- Position of first interpolated point within line [m]
                * **dmax** (*float*) -- Position of last interpolated point within line [m]



   .. py:method:: interpol_2D(dx=0.2, dy=0.2)

      Routine interpolates data on all lines onto a regular grid. No extrapolation
      is done, i.e. if at the beginning or the end of a line data are missing
      (the line starts later than others or stops earlier), the interpolated
      array will contain nans
      The interpolation method used is scipy.interpolate.CloughTocher2DInterpolator

      :param dx: Sampling step in meters in x-direction. The default is 0.2.
      :type dx: float, optional
      :param dx: Sampling step in meters in y-direction. The default is 0.2.
      :type dx: float, optional

      :returns: * **sensor1_inter** (*2D numpy float array*) -- Contains gridded data of sensor 1
                * **sensor2_inter** (*2D numpy float array*) -- Contains gridded data of sensor 2
                * **grad_inter** (*2D numpy float array*) -- contains the vertical gradient
                * *The shape of the arrays depends on the principal direction of the lines*
                * *- If self.direction == 1, shape is (number_of_data_points_per_line, number_of_lines)*
                * **- else** (*(number_of_lines, number_of_data_points_per_line)*)
                * **x_inter** (*1D numpy float array*) -- x_coordinates of the columns of s1_inter and s2_inter
                * **y_inter** (*1D numpy float array*) -- y_coordinates of the rows of s1_inter and s2_inter



   .. py:method:: extrapolate(d, x, y)

      Routine fills nans on an interpolated grid.
      For this, it searches first for every line and column the first and last
      existing (non-nan) points. Then, for every non-defined point, it searches
      the "n_nearest" nearest points (see first command line) and associates
      a weighted average value. The weight is calculated as 1/distance**2

      :param d: Contains data on regular grid. NaN for inexistant data. Shape: (ny,nx)
      :type d: 2D numpy array
      :param x: Coordiantes of the columns of data
      :type x: 1D numpy array
      :param y: Coordiantes of the rows of data
      :type y: 1D numpy array

      :returns: **data** -- Contains full regular grid of data
      :rtype: 2D numpy array with the same shape as input data.



   .. py:method:: justify_lines_median(just=0, inplace=True)

      Often the measurment direction has an influence on magnetic data due to
      uncorrected effects of acquisition instrumentation.
      The function calculates the median values of every line and adjusts the
      one of every second line to the average median of the neighbouring lines

      :param just: If 0: Leave medians of even line (python counting, i.e. first line is even)
                   untouched, justify odd lines to medians of even lines.
                   If 1: Do the reverse
      :type just: int, optional
      :param inplace: if True, justified data are back-copied to self.sensorN_inter and True
                      is returned. If not, new arrays are returned The default is True.
      :type inplace: bool, optional

      :returns: * **s1_justified** (*1D numpy array with justified data of first sensor*)
                * **s2_justified** (*1D numpy array with justified data of second sensor*)



   .. py:method:: gauss_transform(data_fix, data_move)

      Transforms data sets to gaussian distribution does a projection
      of the second data set onto the distribution of the first and returns
      the back-transformed modified second data set

      :param data_fix: Reference data set.
      :type data_fix: numpy 1D array
      :param data_move: Data set to be projected onto the gaussian distribution of data_fix.
      :type data_move: numpy 1D array

      :returns: Modified data_move array.
      :rtype: numpy 1D array



   .. py:method:: justify_lines_gaussian(just=0, local=1, inplace=True)

      Often the measurment direction has an influence on magnetic data due to
      uncorrected effects of acquisition instrumentation.
      The function calculates the median values of every line and adjusts the
      one of every second line to the average median of the neighbouring lines

      :param just: If 0: Leve medians of even line (python counting, i.e. first line is even)
                   untouched, justify odd lines to medians of even lines
                   If 1: Do the reverse
      :type just: int, optional
      :param local: If 0: apply gaussian transform to the whole data set
                    If 1: apply gaussian transform only to neighboring lines
      :type local: int, optional
      :param inplace: If True, justified data are back-copied to self.sensorN_inter and True
                      is returned. If not, new arrays are returned The default is True.
      :type inplace: bool, optional

      :returns: * **s1_justified** (*2D numpy float array*) -- Justified data of first sensor
                * **s2_justified** (*2D numpy float array*) -- Justified data of second sensor



   .. py:method:: matrixExtension(data)

      Creation of extended matix for 2D Fourier transform.
      The toutine mirrors the lower half of the matrix and adds it at the bottom
      and mirrors the upper half to the top. Equivalently right and left

      :param data: Data matrix to be extended
      :type data: 2D numpy array

      :returns: **d** -- (ny1,nx1): Tuple with starting indices of the original data in matrix d
                (ny2,nx2): Tuple with final indices of the original data in matrix d plus one
                The original data may thus be retrieved as
                data = d[ny1:ny2,nx1:nx2]
      :rtype: 2D numpy array extended in both directions



   .. py:method:: pole_Reduction(data, dx, dy, Inc, Dec)

      Calculation of pole-reduced magnetic data supposing only induced magnetization
      Formula from Keating and Zerbo, Geophysics 61, n·µí 1 (1996): 131‚Äë137.


      :param data: Original magnetic data interpolated on a regular grid which may have
                   different grid width in x (E-W) and y (N-S) direction.
      :type data: 2D numpy float array
      :param dx: grid step in x direction.
      :type dx: float
      :param dy: grid step in y direction.
      :type dy: float
      :param Inc: Inclination of magnetic field [degrees].
      :type Inc: float
      :param Dec: Declination of magnetic field [degrees].
      :type Dec: float

      :returns: **d** -- Reduced to the pole magnetic data
      :rtype: 2D numpy float array with the same shape as data



   .. py:method:: continuation(data, dx, dy, dz)

      Vertical continuation of potential field data using Fourier transform

      :param data: Data interpolated onto a regular grid
      :type data: 2D numpy float array
      :param dx: Grid spacing in x and y direction [m]
      :type dx: float
      :param dy: Grid spacing in x and y direction [m]
      :type dy: float
      :param dz: Distance to continue data [m], positive upwards
      :type dz: float

      :returns: Prolongated data
      :rtype: 2D numpy float array, same shape as data



   .. py:method:: analyticSignal(data, dx, dy)

      Calculation of analytical signal of potential field data via
      vertical and horizontal derivatives

      :param data: Data interpolated onto a regular grid
      :type data: 2D numpy float array
      :param dx: Grid spacing in x and y direction [m]
      :type dx: float
      :param dy: Grid spacing in x and y direction [m]
      :type dy: float

      :returns: Analytic signal
      :rtype: 2D numpy float array, same shape as data



   .. py:method:: horizontalDerivative2(data, dx, dy)

      Second horizontal derivative of potential field data using Fourier transform

      :param data: Data interpolated onto a regular grid
      :type data: 2D numpy float array
      :param dx: Grid spacing in x and y direction [m]
      :type dx: float
      :param dy: Grid spacing in x and y direction [m]
      :type dy: float

      :returns: 2nd horizontal derivative of data
      :rtype: 2D numpy float array, same shape as data



   .. py:method:: horizontalDerivative(data, dx, dy)

      First horizontal derivative of potential field data using Fourier transform

      :param data: Data interpolated onto a regular grid
      :type data: 2D numpy float array
      :param dx: Grid spacing in x and y direction [m]
      :type dx: float
      :param dy: Grid spacing in x and y direction [m]
      :type dy: float

      :returns: First horizontal derivative of data
      :rtype: 2D numpy float array, same shape as data



   .. py:method:: verticalDerivative2(data)

      Second vertical derivative of potential field data using finite differences

      :param data: Data interpolated onto a regular grid
      :type data: 2D numpy float array

      :returns: 2nd vertical derivative of data
      :rtype: 2D numpy float array, same shape as data



   .. py:method:: verticalDerivative(data, dx, dy)

      First vertical derivative of potential field data using Fourier transform

      :param data: Data interpolated onto a regular grid
      :type data: 2D numpy float array
      :param dx: Grid spacing in x and y direction [m]
      :type dx: float
      :param dy: Grid spacing in x and y direction [m]
      :type dy: float

      :returns: First vertical derivative of data
      :rtype: 2D numpy float array, same shape as data



   .. py:method:: tilt(data, grad, dx, dy)

      Tilt angle of potential field data using Fourier transform

      :param data: Data interpolated onto a regular grid
      :type data: 2D numpy float array
      :param grad: Vertical derivative of data if it has been measured
      :type grad: 2D numpy float array
      :param dx: Grid spacing in x and y direction [m]
      :type dx: float
      :param dy: Grid spacing in x and y direction [m]
      :type dy: float

      :returns: Tilt angle of data
      :rtype: 2D numpy float array, same shape as data



